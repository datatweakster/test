{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "231ec97a-bcf7-44b8-8d00-0c749fb80914",
   "metadata": {},
   "source": [
    "### **Data Modeling**\n",
    "#### **1. What is data modeling, and why is it important?**\n",
    "**Sample Answer:**  \n",
    "Data modeling is the process of defining and structuring data elements and their relationships to support business processes. It ensures data consistency, improves data integrity, and enhances query performance by creating optimized database schemas. Data models are essential for designing efficient databases that meet business needs.\n",
    "\n",
    "#### **2. Can you explain the difference between conceptual, logical, and physical data models?**\n",
    "**Sample Answer:**  \n",
    "- **Conceptual Data Model:** High-level representation of data, focusing on business entities and relationships without technical details.  \n",
    "- **Logical Data Model:** Defines attributes, primary and foreign keys, and relationships in more detail but remains independent of a specific database system.  \n",
    "- **Physical Data Model:** Represents how the data will be stored in the database, including table structures, indexes, and constraints.\n",
    "\n",
    "#### **3. What is normalization, and why is it important?**\n",
    "**Sample Answer:**  \n",
    "Normalization is the process of structuring a relational database to reduce data redundancy and improve data integrity. It involves dividing large tables into smaller ones and defining relationships. It helps avoid anomalies in data insertion, deletion, and updating while improving efficiency.\n",
    "\n",
    "#### **4. What are the key differences between OLTP and OLAP databases?**\n",
    "**Sample Answer:**  \n",
    "- **OLTP (Online Transaction Processing):** Used for transactional systems, supports real-time operations, and ensures quick insert, update, and delete operations.  \n",
    "- **OLAP (Online Analytical Processing):** Designed for analytical workloads, optimized for read-heavy queries, and supports complex aggregations for business intelligence and reporting.\n",
    "\n",
    "---\n",
    "\n",
    "### **ETL (Extract, Transform, Load)**\n",
    "#### **5. What is ETL, and why is it necessary in data warehousing?**\n",
    "**Sample Answer:**  \n",
    "ETL stands for Extract, Transform, and Load. It is a process used to collect data from different sources (Extract), clean and structure it (Transform), and store it in a data warehouse (Load). ETL ensures data consistency, accuracy, and availability for reporting and analytics.\n",
    "\n",
    "#### **6. Can you explain the difference between ETL and ELT?**\n",
    "**Sample Answer:**  \n",
    "- **ETL (Extract, Transform, Load):** Data is transformed before being loaded into the data warehouse. Suitable for structured data processing.  \n",
    "- **ELT (Extract, Load, Transform):** Data is first loaded into the data warehouse and then transformed using SQL or other processing tools. Preferred for big data environments.\n",
    "\n",
    "#### **7. What are some common ETL challenges, and how do you overcome them?**\n",
    "**Sample Answer:**  \n",
    "- **Data Quality Issues:** Use data validation rules and logging mechanisms.  \n",
    "- **Performance Bottlenecks:** Optimize queries, indexing, and partitioning.  \n",
    "- **Handling Large Data Volumes:** Implement parallel processing and incremental data loading strategies.  \n",
    "- **Error Handling & Monitoring:** Implement retry mechanisms and logging for failed jobs.\n",
    "\n",
    "#### **8. How would you design an ETL pipeline for processing customer transactions?**\n",
    "**Sample Answer:**  \n",
    "- **Extract:** Collect transaction data from multiple sources (databases, APIs, logs).  \n",
    "- **Transform:** Clean the data, normalize formats, handle missing values, and perform calculations (e.g., total transaction amount).  \n",
    "- **Load:** Store transformed data in a data warehouse for reporting and analytics.\n",
    "\n",
    "---\n",
    "\n",
    "### **Python**\n",
    "#### **9. How can Python be used in data processing and ETL workflows?**\n",
    "**Sample Answer:**  \n",
    "Python provides libraries like **Pandas, NumPy, PySpark, and SQLAlchemy** for data manipulation, transformation, and integration with databases. **Airflow and Luigi** are popular frameworks for managing ETL workflows.\n",
    "\n",
    "#### **10. Write a Python script to read a CSV file and clean missing values.**\n",
    "**Sample Answer:**\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Fill missing values with mean\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv(\"cleaned_data.csv\", index=False)\n",
    "\n",
    "print(\"Data cleaned and saved successfully.\")\n",
    "```\n",
    "\n",
    "#### **11. What is the difference between a list, tuple, and dictionary in Python?**\n",
    "**Sample Answer:**  \n",
    "- **List:** Mutable, ordered collection (e.g., `[1, 2, 3]`).  \n",
    "- **Tuple:** Immutable, ordered collection (e.g., `(1, 2, 3)`).  \n",
    "- **Dictionary:** Key-value pairs, unordered (e.g., `{\"name\": \"Alice\", \"age\": 30}`).\n",
    "\n",
    "#### **12. What are lambda functions in Python, and how are they useful?**\n",
    "**Sample Answer:**  \n",
    "Lambda functions are anonymous, single-line functions in Python used for short, simple operations.  \n",
    "Example:\n",
    "```python\n",
    "square = lambda x: x * x\n",
    "print(square(5))  # Output: 25\n",
    "```\n",
    "They are commonly used in functions like `map()`, `filter()`, and `sorted()`.\n",
    "\n",
    "---\n",
    "\n",
    "### **SQL**\n",
    "#### **13. What are the different types of joins in SQL?**\n",
    "**Sample Answer:**  \n",
    "- **INNER JOIN:** Returns matching records from both tables.  \n",
    "- **LEFT JOIN:** Returns all records from the left table and matching records from the right.  \n",
    "- **RIGHT JOIN:** Returns all records from the right table and matching records from the left.  \n",
    "- **FULL JOIN:** Returns all records from both tables, with NULLs where there’s no match.\n",
    "\n",
    "#### **14. Write an SQL query to find duplicate records in a table.**\n",
    "**Sample Answer:**\n",
    "```sql\n",
    "SELECT column_name, COUNT(*)\n",
    "FROM table_name\n",
    "GROUP BY column_name\n",
    "HAVING COUNT(*) > 1;\n",
    "```\n",
    "\n",
    "#### **15. How do you optimize SQL queries for better performance?**\n",
    "**Sample Answer:**  \n",
    "- Use **indexes** on frequently queried columns.  \n",
    "- Avoid **SELECT***; specify only required columns.  \n",
    "- Optimize **JOINs** by indexing keys properly.  \n",
    "- Use **EXPLAIN PLAN** to analyze query execution.  \n",
    "- Implement **partitioning** for large tables.\n",
    "\n",
    "#### **16. Write an SQL query to get the top 5 highest-paid employees from a table.**\n",
    "**Sample Answer:**\n",
    "```sql\n",
    "SELECT employee_name, salary\n",
    "FROM employees\n",
    "ORDER BY salary DESC\n",
    "LIMIT 5;\n",
    "```\n",
    "\n",
    "#### **17. What is a stored procedure, and when should you use it?**\n",
    "**Sample Answer:**  \n",
    "A stored procedure is a precompiled SQL code that can be executed multiple times. It improves performance, enhances security, and simplifies database management by encapsulating logic. Stored procedures are used for repetitive tasks like data validation, batch processing, and ETL workflows.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc84030-05de-4a53-9e04-77187c36cbd5",
   "metadata": {},
   "source": [
    "### **Data Modeling**\n",
    "#### **18. What is a star schema, and how does it compare to a snowflake schema?**\n",
    "**Sample Answer:**  \n",
    "A **star schema** is a database structure where a central fact table connects to multiple dimension tables, making queries simple and fast.  \n",
    "A **snowflake schema** normalizes dimension tables by breaking them into sub-dimensions, reducing redundancy but increasing complexity.\n",
    "\n",
    "**Example:**  \n",
    "- **Star Schema:**  \n",
    "  - `fact_sales (sales_id, product_id, customer_id, date, amount)`\n",
    "  - `dim_product (product_id, name, category)`\n",
    "  - `dim_customer (customer_id, name, location)`\n",
    "  \n",
    "- **Snowflake Schema:**  \n",
    "  - `dim_product (product_id, name, category_id)`\n",
    "  - `dim_category (category_id, category_name)`\n",
    "\n",
    "Use **star schema** for better performance in OLAP and **snowflake schema** for normalized data storage.\n",
    "\n",
    "#### **19. How would you design a data model for tracking concert ticket sales?**\n",
    "**Sample Answer:**  \n",
    "**Entities:**\n",
    "- **Customers** (customer_id, name, email, phone)\n",
    "- **Concerts** (concert_id, artist, venue, date, time)\n",
    "- **Tickets** (ticket_id, customer_id, concert_id, price, seat_number)\n",
    "- **Payments** (payment_id, customer_id, amount, date, method)\n",
    "\n",
    "**Relationships:**  \n",
    "- One **customer** can buy multiple **tickets**.  \n",
    "- One **concert** can have multiple **tickets sold**.  \n",
    "- One **ticket** is linked to a **payment transaction**.\n",
    "\n",
    "Using a **star schema** would make querying total revenue, popular concerts, and sales trends easier.\n",
    "\n",
    "#### **20. What is a surrogate key, and when should you use it?**\n",
    "**Sample Answer:**  \n",
    "A **surrogate key** is a system-generated unique identifier (e.g., an auto-incremented ID) that replaces a natural key.  \n",
    "Use it when:\n",
    "- Natural keys are long or subject to change.\n",
    "- Relationships involve complex composite keys.\n",
    "- Data integrity and performance optimization are needed.\n",
    "\n",
    "---\n",
    "\n",
    "### **ETL (Extract, Transform, Load)**\n",
    "#### **21. How would you design an ETL pipeline for real-time data ingestion?**\n",
    "**Sample Answer:**  \n",
    "A **real-time ETL pipeline** consists of:\n",
    "1. **Extract:** Use **Kafka, AWS Kinesis, or RabbitMQ** to stream data from sources.\n",
    "2. **Transform:** Process data using **Apache Flink, Spark Streaming, or Python scripts**.\n",
    "3. **Load:** Store transformed data in **a NoSQL DB (MongoDB) for quick access** and **a data warehouse (Snowflake, Redshift) for analytics**.\n",
    "\n",
    "For example, in **a concert ticketing system**, real-time ETL helps detect ticket availability, fraud detection, and dynamic pricing.\n",
    "\n",
    "#### **22. What strategies would you use to handle slowly changing dimensions (SCDs)?**\n",
    "**Sample Answer:**  \n",
    "**SCDs** track changes in dimension tables over time. Common types:  \n",
    "- **SCD Type 1:** Overwrites old data (e.g., updating customer email).  \n",
    "- **SCD Type 2:** Creates a new record with a version or timestamp (e.g., tracking a customer’s address history).  \n",
    "- **SCD Type 3:** Adds a new column for historical values (e.g., storing the previous and current region of a user).\n",
    "\n",
    "#### **23. How would you optimize an ETL process that is running too slowly?**\n",
    "**Sample Answer:**  \n",
    "- **Optimize extraction:** Use bulk loading instead of row-by-row inserts.\n",
    "- **Optimize transformation:** Apply partitioning and parallel processing.\n",
    "- **Optimize loading:** Use indexing, compression, and batch processing.\n",
    "- **Implement incremental loading:** Process only new/updated records instead of full loads.\n",
    "- **Use caching mechanisms:** Store frequently accessed data in memory.\n",
    "\n",
    "---\n",
    "\n",
    "### **Python**\n",
    "#### **24. How would you use Python to automate an ETL pipeline?**\n",
    "**Sample Answer:**  \n",
    "Use **Pandas for data transformation**, **SQLAlchemy for database connections**, and **Airflow for orchestration**.\n",
    "\n",
    "Example Python script:\n",
    "```python\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Extract\n",
    "df = pd.read_csv(\"raw_data.csv\")\n",
    "\n",
    "# Transform\n",
    "df[\"amount\"] = df[\"amount\"].fillna(0)  # Handle missing values\n",
    "\n",
    "# Load\n",
    "engine = create_engine(\"mysql://user:password@localhost/db\")\n",
    "df.to_sql(\"cleaned_data\", con=engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\"ETL pipeline completed.\")\n",
    "```\n",
    "---\n",
    "\n",
    "#### **25. How would you handle large datasets efficiently in Python?**\n",
    "**Sample Answer:**  \n",
    "- Use **Dask** or **PySpark** instead of Pandas for distributed processing.\n",
    "- Use **iterators** and **generators** instead of loading entire datasets into memory.\n",
    "- Optimize SQL queries and avoid unnecessary computations.\n",
    "\n",
    "Example using Dask:\n",
    "```python\n",
    "import dask.dataframe as dd\n",
    "df = dd.read_csv(\"large_data.csv\")\n",
    "df.groupby(\"category\").mean().compute()\n",
    "```\n",
    "---\n",
    "\n",
    "#### **26. How would you detect and handle duplicate records in Python?**\n",
    "**Sample Answer:**  \n",
    "Using Pandas:\n",
    "```python\n",
    "df = df.drop_duplicates()\n",
    "```\n",
    "If keeping the latest record:\n",
    "```python\n",
    "df = df.sort_values(\"date\").drop_duplicates(subset=[\"customer_id\"], keep=\"last\")\n",
    "```\n",
    "---\n",
    "\n",
    "### **SQL**\n",
    "#### **27. Write an SQL query to calculate the total sales per concert.**\n",
    "```sql\n",
    "SELECT concert_id, SUM(price) AS total_sales\n",
    "FROM tickets\n",
    "GROUP BY concert_id;\n",
    "```\n",
    "---\n",
    "\n",
    "#### **28. How do you retrieve the second highest salary from an employee table?**\n",
    "```sql\n",
    "SELECT DISTINCT salary \n",
    "FROM employees \n",
    "ORDER BY salary DESC \n",
    "LIMIT 1 OFFSET 1;\n",
    "```\n",
    "---\n",
    "\n",
    "#### **29. How would you troubleshoot slow SQL queries?**\n",
    "**Sample Answer:**  \n",
    "- Use `EXPLAIN ANALYZE` to check query execution plans.\n",
    "- Create indexes on columns used in WHERE, JOIN, and GROUP BY.\n",
    "- Optimize joins by reducing the number of scanned rows.\n",
    "- Use `LIMIT` to test queries on smaller datasets.\n",
    "- Avoid `SELECT *` and retrieve only required columns.\n",
    "\n",
    "---\n",
    "\n",
    "#### **30. Write an SQL query to find customers who have purchased tickets for multiple concerts.**\n",
    "```sql\n",
    "SELECT customer_id\n",
    "FROM tickets\n",
    "GROUP BY customer_id\n",
    "HAVING COUNT(DISTINCT concert_id) > 1;\n",
    "```\n",
    "---\n",
    "\n",
    "#### **31. How would you join three tables in SQL?**\n",
    "**Sample Answer:**  \n",
    "Example of joining `customers`, `tickets`, and `concerts`:\n",
    "```sql\n",
    "SELECT c.name, co.artist, t.price\n",
    "FROM customers c\n",
    "JOIN tickets t ON c.customer_id = t.customer_id\n",
    "JOIN concerts co ON t.concert_id = co.concert_id;\n",
    "```\n",
    "---\n",
    "\n",
    "### **Scenario-Based Questions**\n",
    "#### **32. A manager wants to track concert ticket sales trends. What KPIs and reports would you suggest?**\n",
    "**Sample Answer:**  \n",
    "KPIs:\n",
    "- Total revenue per concert.\n",
    "- Ticket sales trends over time.\n",
    "- Most popular concerts based on demand.\n",
    "- Customer demographics and purchase behavior.\n",
    "\n",
    "Reports:\n",
    "- Daily/weekly sales performance.\n",
    "- Customer retention and repeat purchase trends.\n",
    "- Heatmaps showing ticket purchases by location.\n",
    "\n",
    "---\n",
    "\n",
    "#### **33. How would you detect fraudulent transactions in a ticketing system?**\n",
    "**Sample Answer:**  \n",
    "- Identify **suspiciously high ticket purchases** from a single user.\n",
    "- Track **multiple purchases from the same IP address**.\n",
    "- Flag transactions with **mismatched location and payment details**.\n",
    "- Use **machine learning models** to detect anomalies.\n",
    "\n",
    "SQL query to detect duplicate payments:\n",
    "```sql\n",
    "SELECT customer_id, COUNT(*)\n",
    "FROM payments\n",
    "WHERE amount > 1000\n",
    "GROUP BY customer_id\n",
    "HAVING COUNT(*) > 3;\n",
    "```\n",
    "---\n",
    "\n",
    "#### **34. How would you design a database for loyalty rewards in the concert system?**\n",
    "**Sample Answer:**  \n",
    "**Tables:**\n",
    "- `customers (customer_id, name, email, points)`\n",
    "- `transactions (transaction_id, customer_id, amount, points_earned)`\n",
    "- `rewards (reward_id, description, points_required)`\n",
    "\n",
    "**Logic:**\n",
    "- Earn points for each ticket purchase.\n",
    "- Redeem points for discounts or VIP access.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4b22ef-81d9-4f63-a8fe-e9e2569adac0",
   "metadata": {},
   "source": [
    "### **Hadoop Basics**\n",
    "#### **1. What is Hadoop, and why is it used?**  \n",
    "**Sample Answer:**  \n",
    "Hadoop is an **open-source framework** for processing and storing large datasets in a **distributed computing environment**. It enables **scalable, fault-tolerant, and parallel processing** using commodity hardware. Hadoop is mainly used for **big data analytics, batch processing, and unstructured data storage**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. What are the core components of the Hadoop ecosystem?**  \n",
    "**Sample Answer:**  \n",
    "The Hadoop ecosystem consists of several core components:  \n",
    "- **HDFS (Hadoop Distributed File System):** A distributed file storage system.  \n",
    "- **MapReduce:** A parallel processing framework for large-scale data processing.  \n",
    "- **YARN (Yet Another Resource Negotiator):** Manages cluster resources and job scheduling.  \n",
    "- **HBase:** A NoSQL database for real-time read/write operations.  \n",
    "- **Hive:** A SQL-like querying tool for Hadoop.  \n",
    "- **Pig:** A high-level scripting language for data processing.  \n",
    "- **Sqoop:** A tool for transferring data between Hadoop and relational databases.  \n",
    "- **Flume:** A tool for ingesting log data into Hadoop.\n",
    "\n",
    "---\n",
    "\n",
    "### **HDFS (Hadoop Distributed File System)**\n",
    "#### **3. What are the key features of HDFS?**  \n",
    "**Sample Answer:**  \n",
    "- **Distributed Storage:** Data is split into blocks and stored across multiple nodes.  \n",
    "- **Fault Tolerance:** Data is replicated across nodes to prevent data loss.  \n",
    "- **Scalability:** Can handle petabytes of data across thousands of machines.  \n",
    "- **Write-Once, Read-Many:** Data can be written once and read multiple times.  \n",
    "- **Automatic Data Balancing:** Hadoop automatically manages data distribution.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. How does Hadoop handle node failures?**  \n",
    "**Sample Answer:**  \n",
    "Hadoop handles node failures using **data replication**. When a node fails:  \n",
    "- **HDFS automatically replicates missing data from other nodes.**  \n",
    "- **YARN reschedules jobs to available nodes.**  \n",
    "- **A NameNode monitors active and failed DataNodes.**  \n",
    "- **Replication factors ensure multiple copies exist.**  \n",
    "\n",
    "Example: If a block is stored with a **replication factor of 3**, it exists on three different nodes. If one node fails, the data is still available from the other two.\n",
    "\n",
    "---\n",
    "\n",
    "### **MapReduce**\n",
    "#### **5. What is MapReduce, and how does it work?**  \n",
    "**Sample Answer:**  \n",
    "MapReduce is a **programming model** for processing large datasets in a **distributed and parallel** manner.  \n",
    "It consists of two phases:  \n",
    "1. **Map Phase:** Processes input data and converts it into key-value pairs.  \n",
    "2. **Reduce Phase:** Aggregates and processes key-value pairs to generate final results.  \n",
    "\n",
    "Example: Word count using MapReduce  \n",
    "- **Map:** Read text and output (word, 1) pairs.  \n",
    "- **Reduce:** Sum up values for each word.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **6. What are the advantages and limitations of MapReduce?**  \n",
    "**Sample Answer:**  \n",
    "✅ **Advantages:**  \n",
    "- Handles **large-scale data processing**.  \n",
    "- Provides **automatic parallelization** and **fault tolerance**.  \n",
    "- Works efficiently with **structured and unstructured data**.  \n",
    "\n",
    "❌ **Limitations:**  \n",
    "- **Batch-oriented:** Not suitable for real-time processing.  \n",
    "- **I/O heavy:** Requires reading/writing from disk frequently.  \n",
    "- **Complex coding:** Requires Java or Python knowledge for implementation.  \n",
    "\n",
    "---\n",
    "\n",
    "### **YARN (Yet Another Resource Negotiator)**\n",
    "#### **7. What is YARN, and why is it important in Hadoop?**  \n",
    "**Sample Answer:**  \n",
    "YARN is the **resource management layer** in Hadoop. It allows multiple applications (MapReduce, Spark, etc.) to run on the same cluster by efficiently allocating CPU, memory, and storage resources.  \n",
    "\n",
    "**YARN components:**  \n",
    "- **ResourceManager:** Allocates resources across applications.  \n",
    "- **NodeManager:** Monitors resources on each node.  \n",
    "- **ApplicationMaster:** Manages application execution.  \n",
    "\n",
    "YARN improves **scalability, efficiency, and multi-tenancy** in Hadoop.\n",
    "\n",
    "---\n",
    "\n",
    "### **Hadoop vs Other Big Data Technologies**\n",
    "#### **8. How does Hadoop compare to Spark?**  \n",
    "**Sample Answer:**  \n",
    "| Feature | Hadoop (MapReduce) | Apache Spark |\n",
    "|---------|-------------------|-------------|\n",
    "| **Processing** | Batch processing | Real-time & batch |\n",
    "| **Speed** | Disk-based, slower | In-memory, much faster |\n",
    "| **Ease of Use** | Complex (Java required) | Easier (supports Python, Scala, R) |\n",
    "| **Fault Tolerance** | Uses data replication | Uses RDD lineage |\n",
    "| **Best Use Cases** | Large-scale batch jobs | Real-time analytics & ML |\n",
    "\n",
    "**Example:** If you need **real-time fraud detection**, use **Spark**. If you need **processing petabytes of log data**, use **Hadoop MapReduce**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Hadoop Data Ingestion**\n",
    "#### **9. What is the difference between Sqoop and Flume?**  \n",
    "**Sample Answer:**  \n",
    "- **Sqoop:** Used for **batch data transfer** between Hadoop and relational databases (MySQL, PostgreSQL).  \n",
    "- **Flume:** Used for **real-time streaming** of log data into Hadoop (e.g., web server logs).  \n",
    "\n",
    "**Example Use Case:**  \n",
    "- Use **Sqoop** to import historical sales data from MySQL to Hadoop.  \n",
    "- Use **Flume** to stream real-time website click logs into HDFS.\n",
    "\n",
    "---\n",
    "\n",
    "#### **10. How would you ingest large datasets into Hadoop?**  \n",
    "**Sample Answer:**  \n",
    "1. **Batch Processing:** Use **Sqoop** for structured data imports from RDBMS.  \n",
    "2. **Streaming Data:** Use **Flume or Kafka** for log and real-time event data.  \n",
    "3. **File Transfer:** Use **HDFS commands** or **DistCp** for copying large files.  \n",
    "4. **Custom ETL Pipelines:** Use **Python, Apache NiFi, or Airflow** for automating ingestion.\n",
    "\n",
    "---\n",
    "\n",
    "### **Hadoop Performance Optimization**\n",
    "#### **11. How would you optimize Hadoop job performance?**  \n",
    "**Sample Answer:**  \n",
    "- **Increase parallelism:** Use more nodes and increase mappers/reducers.  \n",
    "- **Use compression:** Store files in **Parquet** or **ORC** format to reduce size.  \n",
    "- **Tune block size:** Increase HDFS block size for large files (default: 128MB).  \n",
    "- **Use combiners:** Reduce data shuffling in MapReduce.  \n",
    "- **Partition data:** Distribute data based on keys for better load balancing.  \n",
    "\n",
    "Example: Changing the default replication factor from **3 to 2** can save storage space.\n",
    "\n",
    "---\n",
    "\n",
    "#### **12. How does Hadoop handle small files efficiently?**  \n",
    "**Sample Answer:**  \n",
    "Hadoop is optimized for **large files**, but small files cause **high NameNode memory usage**. To handle small files:  \n",
    "- Use **HAR (Hadoop Archive Files)** to merge small files.  \n",
    "- Use **SequenceFiles** to store multiple files as key-value pairs.  \n",
    "- Use **HBase** for frequent small file updates.  \n",
    "- Increase **HDFS block size** to accommodate more data per block.\n",
    "\n",
    "---\n",
    "\n",
    "### **Hadoop Security**\n",
    "#### **13. How does Hadoop ensure security?**  \n",
    "**Sample Answer:**  \n",
    "Hadoop provides security through:  \n",
    "- **Kerberos authentication:** Ensures secure user access.  \n",
    "- **HDFS permissions & ACLs:** Restrict file access.  \n",
    "- **Encryption:** Protects data at rest and in transit.  \n",
    "- **Ranger & Sentry:** Provide fine-grained access control.  \n",
    "\n",
    "Example: In **a financial application**, you can use **Kerberos authentication** to prevent unauthorized access to transaction data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Hadoop Use Cases**\n",
    "#### **14. What are some real-world use cases of Hadoop?**  \n",
    "**Sample Answer:**  \n",
    "- **Banking & Fraud Detection:** Analyzing transaction data for fraud patterns.  \n",
    "- **E-commerce Recommendations:** Processing customer behavior for product recommendations.  \n",
    "- **Healthcare Analytics:** Storing and analyzing large-scale patient records.  \n",
    "- **Log Analysis:** Processing server logs for performance monitoring.  \n",
    "\n",
    "Example: **Netflix** uses Hadoop to **analyze streaming patterns and optimize recommendations**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151aeeaa-0f70-413a-a020-6f68572e7abb",
   "metadata": {},
   "source": [
    "### Banking\n",
    "\n",
    "### 1. Can you explain the key performance indicators (KPIs) you would monitor for a credit card portfolio?\n",
    "\n",
    "**Sample Answer:**\n",
    "\n",
    "Monitoring the performance of a credit card portfolio involves tracking several KPIs, including:\n",
    "\n",
    "- **Delinquency Rate:** Measures the percentage of accounts past due, indicating potential credit risk.\n",
    "\n",
    "- **Net Charge-Off Rate:** Represents the amount of debt unlikely to be collected, reflecting the quality of the credit portfolio.\n",
    "\n",
    "- **Activation Rate:** The proportion of issued cards that are actively used, assessing customer engagement.\n",
    "\n",
    "- **Average Spend per Account:** Evaluates card usage and helps in understanding customer spending behaviors.\n",
    "\n",
    "- **Customer Retention Rate:** Indicates the percentage of customers who continue to use the card over time, essential for long-term profitability.\n",
    "\n",
    "Regularly analyzing these KPIs helps in making informed decisions to enhance portfolio performance.\n",
    "\n",
    "### 2. How would you approach analyzing the profitability of a new credit card product?\n",
    "\n",
    "**Sample Answer:**\n",
    "\n",
    "Analyzing the profitability of a new credit card product involves several steps:\n",
    "\n",
    "1. **Market Research:** Assess the target market to estimate potential customer acquisition and usage rates.\n",
    "\n",
    "2. **Revenue Streams:** Identify all possible income sources, such as interest income, annual fees, late fees, and interchange fees.\n",
    "\n",
    "3. **Cost Analysis:** Calculate costs, including customer acquisition expenses, operational costs, rewards programs, and potential credit losses.\n",
    "\n",
    "4. **Break-Even Analysis:** Determine the point at which revenues equal costs to understand the viability of the product.\n",
    "\n",
    "5. **Sensitivity Analysis:** Evaluate how changes in key assumptions (e.g., default rates, spending behaviors) impact profitability.\n",
    "\n",
    "This comprehensive approach ensures a thorough understanding of the financial prospects of the new product.\n",
    "\n",
    "### 3. Describe a time when you used data analysis to identify and solve a problem related to credit card usage.\n",
    "\n",
    "**Sample Answer:**\n",
    "\n",
    "In my previous role, I noticed a decline in the average transaction value among our credit card users. By analyzing transaction data, I identified that a significant number of customers were using their cards primarily for small, everyday purchases.\n",
    "\n",
    "To address this, I collaborated with the marketing team to develop a campaign promoting the benefits of using the card for larger purchases, such as cashback offers and extended warranties. Post-campaign, we observed a 15% increase in the average transaction value over the next quarter.\n",
    "\n",
    "### 4. How do you assess the creditworthiness of potential credit card applicants?\n",
    "\n",
    "**Sample Answer:**\n",
    "\n",
    "Assessing the creditworthiness of applicants involves evaluating several factors:\n",
    "\n",
    "- **Credit Score:** Provides a snapshot of the applicant's credit history and reliability.\n",
    "\n",
    "- **Income and Employment History:** Ensures the applicant has a stable income to meet repayment obligations.\n",
    "\n",
    "- **Debt-to-Income Ratio:** Calculates existing debt relative to income to assess additional debt capacity.\n",
    "\n",
    "- **Payment History:** Reviews past payment behaviors to predict future reliability.\n",
    "\n",
    "- **Existing Credit Lines:** Examines current credit accounts to evaluate credit management skills.\n",
    "\n",
    "By analyzing these factors, we can make informed decisions on extending credit while mitigating risk.\n",
    "\n",
    "### 5. What strategies would you implement to reduce credit card fraud?\n",
    "\n",
    "**Sample Answer:**\n",
    "\n",
    "Reducing credit card fraud requires a multifaceted approach:\n",
    "\n",
    "- **Advanced Fraud Detection Systems:** Implement machine learning algorithms to detect unusual spending patterns in real-time.\n",
    "\n",
    "- **Two-Factor Authentication (2FA):** Require additional verification for online transactions to enhance security.\n",
    "\n",
    "- **Regular Account Monitoring:** Proactively monitor accounts for suspicious activities and alert customers promptly.\n",
    "\n",
    "- **Customer Education:** Inform customers about safe practices, such as recognizing phishing attempts and safeguarding personal information.\n",
    "\n",
    "- **Collaboration with Law Enforcement:** Work closely with authorities to track and prevent fraudulent activities.\n",
    "\n",
    "Implementing these strategies can significantly reduce the incidence of fraud and protect both the company and its customers.\n",
    "\n",
    "### 6. How do you stay updated with regulatory changes affecting the credit card industry?\n",
    "\n",
    "**Sample Answer:**\n",
    "\n",
    "Staying informed about regulatory changes is crucial. I regularly:\n",
    "\n",
    "- **Subscribe to Industry Newsletters:** Receive updates from reputable financial news sources and regulatory bodies.\n",
    "\n",
    "- **Attend Workshops and Seminars:** Participate in events focused on financial regulations and compliance.\n",
    "\n",
    "- **Engage in Professional Networks:** Connect with peers and industry experts to discuss and share insights on emerging regulations.\n",
    "\n",
    "- **Continuous Education:** Enroll in courses and certifications related to financial regulations and compliance.\n",
    "\n",
    "This proactive approach ensures I remain knowledgeable and can adapt to any regulatory changes effectively.\n",
    "\n",
    "### 7. Can you discuss a successful strategy you implemented to increase credit card customer retention?\n",
    "\n",
    "**Sample Answer:**\n",
    "\n",
    "In a previous position, we faced challenges with customer attrition. To combat this, I conducted a thorough analysis to identify common reasons for account closures.\n",
    "\n",
    "Based on the findings, we introduced a personalized rewards program that offered tailored benefits aligning with individual spending habits. Additionally, we enhanced our customer service by providing dedicated support channels for premium customers.\n",
    "\n",
    "As a result, customer retention rates improved by 20% over the following year, and customer satisfaction scores saw a significant uptick.\n",
    "\n",
    "These questions and answers are designed to help you prepare effectively for a Credit Card Business Analyst interview, showcasing your expertise and experience in the field."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfcedb4-797c-479d-ba9f-13aefcf9c25c",
   "metadata": {},
   "source": [
    "## **Credit Card Business & Market Analysis**  \n",
    "\n",
    "### **1. What factors influence credit card customer acquisition and retention?**  \n",
    "**Sample Answer:**  \n",
    "Several factors impact both acquiring and retaining credit card customers:  \n",
    "\n",
    "**For Customer Acquisition:**  \n",
    "- **Attractive Offers & Rewards:** Cashback, travel points, and introductory 0% APR promotions.  \n",
    "- **Competitive Interest Rates & Fees:** Lower fees and competitive APRs attract more applicants.  \n",
    "- **Marketing & Partnerships:** Collaborations with retailers, airlines, and financial institutions.  \n",
    "- **Approval Criteria & Ease of Application:** A seamless and fast approval process.  \n",
    "\n",
    "**For Customer Retention:**  \n",
    "- **Personalized Rewards & Benefits:** Customizing rewards based on spending behavior.  \n",
    "- **Customer Support & Engagement:** 24/7 customer service and quick issue resolution.  \n",
    "- **Loyalty Programs & Incentives:** Retention bonuses for long-term cardholders.  \n",
    "- **Fraud Protection & Security:** Customers feel safer using a secure and reliable card.  \n",
    "\n",
    "By understanding these factors, we can refine acquisition strategies and boost retention.  \n",
    "\n",
    "---\n",
    "\n",
    "### **2. How would you segment credit card customers to improve marketing efforts?**  \n",
    "**Sample Answer:**  \n",
    "Customer segmentation is crucial for **targeted marketing**. I would segment customers based on:  \n",
    "\n",
    "1. **Demographics:** Age, income level, location, and profession.  \n",
    "2. **Spending Behavior:** High spenders vs. low spenders, frequent travelers, online shoppers.  \n",
    "3. **Credit Profile:** Prime, near-prime, and subprime customers based on credit scores.  \n",
    "4. **Product Preference:** Cashback, travel rewards, business, or student credit cards.  \n",
    "5. **Engagement Level:** Active users vs. dormant accounts.  \n",
    "\n",
    "Example: If data shows that young professionals in urban areas spend heavily on dining and entertainment, we can tailor promotions and cashback rewards for those categories.  \n",
    "\n",
    "---\n",
    "\n",
    "### **3. How would you assess the impact of a new credit card fee structure?**  \n",
    "**Sample Answer:**  \n",
    "To evaluate a new **fee structure's impact**, I would:  \n",
    "\n",
    "1. **Conduct Historical Analysis:** Compare similar changes in the past to predict customer response.  \n",
    "2. **Segment Customers:** Identify which groups are most sensitive to fees.  \n",
    "3. **Perform A/B Testing:** Implement the new fee for a small sample group and measure responses.  \n",
    "4. **Analyze Customer Complaints & Churn Rate:** Check for increased complaints or card cancellations.  \n",
    "5. **Monitor Revenue Changes:** Track short-term and long-term financial impact.  \n",
    "\n",
    "Example: If we increase the **annual fee from $95 to $120**, we might lose some price-sensitive customers but gain more revenue from premium users who value benefits.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Risk & Fraud Analysis**  \n",
    "\n",
    "### **4. What methods would you use to detect fraudulent credit card transactions?**  \n",
    "**Sample Answer:**  \n",
    "To detect fraud, I would use a combination of **rule-based** and **machine learning** techniques, such as:  \n",
    "\n",
    "- **Real-time anomaly detection:** Flagging transactions that deviate from normal patterns (e.g., large foreign transactions).  \n",
    "- **Velocity checks:** Identifying multiple high-value transactions in a short time frame.  \n",
    "- **Geolocation analysis:** Checking if the transaction location is inconsistent with previous activity.  \n",
    "- **Behavioral analytics:** Using AI to predict fraud based on user behavior.  \n",
    "- **Blacklisting & Whitelisting:** Blocking known fraudulent merchants or users while allowing trusted transactions.  \n",
    "\n",
    "**Example:** A customer who typically spends $50-$100 per transaction suddenly makes a $5,000 purchase in another country. This would trigger an alert for manual review or automatic blocking.  \n",
    "\n",
    "---\n",
    "\n",
    "### **5. How do you assess credit risk when approving credit card applications?**  \n",
    "**Sample Answer:**  \n",
    "Credit risk assessment includes:  \n",
    "\n",
    "1. **Credit Score Review:** Checking FICO scores to determine repayment history.  \n",
    "2. **Debt-to-Income Ratio (DTI):** Ensuring the applicant’s existing debt is manageable.  \n",
    "3. **Employment & Income Verification:** Evaluating financial stability.  \n",
    "4. **Payment History:** Identifying past delinquencies or bankruptcies.  \n",
    "5. **Behavioral Analytics:** Using predictive models to estimate future repayment likelihood.  \n",
    "\n",
    "For example, an applicant with **a high income but a history of late payments** might still be a high-risk candidate despite financial stability.  \n",
    "\n",
    "---\n",
    "\n",
    "### **6. How would you handle an increase in credit card charge-offs?**  \n",
    "**Sample Answer:**  \n",
    "If **charge-offs (bad debts)** are increasing, I would:  \n",
    "\n",
    "- **Analyze Delinquency Trends:** Identify which customer segments are defaulting.  \n",
    "- **Adjust Credit Scoring Models:** Tighten approval criteria for high-risk profiles.  \n",
    "- **Increase Customer Communication:** Send early warnings, payment reminders, and personalized support for struggling customers.  \n",
    "- **Enhance Collections Strategy:** Offer structured repayment plans before sending accounts to collections.  \n",
    "- **Evaluate Economic Conditions:** Check for macroeconomic factors (e.g., recession) that might be affecting repayment.  \n",
    "\n",
    "Example: If charge-offs are rising among young customers with low credit scores, we might **increase minimum approval criteria or adjust interest rates** to mitigate risk.  \n",
    "\n",
    "---\n",
    "\n",
    "## **SQL & Data Analytics**  \n",
    "\n",
    "### **7. How would you use SQL to analyze credit card transaction patterns?**  \n",
    "**Sample Answer:**  \n",
    "I would write queries to:  \n",
    "\n",
    "1. **Identify high-spending customers:**  \n",
    "   ```sql\n",
    "   SELECT customer_id, SUM(transaction_amount) AS total_spent\n",
    "   FROM transactions\n",
    "   WHERE transaction_date BETWEEN '2024-01-01' AND '2024-12-31'\n",
    "   GROUP BY customer_id\n",
    "   ORDER BY total_spent DESC\n",
    "   LIMIT 10;\n",
    "   ```  \n",
    "   *Finds top 10 spenders in 2024.*  \n",
    "\n",
    "2. **Detect potential fraud (multiple transactions in a short period):**  \n",
    "   ```sql\n",
    "   SELECT customer_id, COUNT(*) AS num_transactions\n",
    "   FROM transactions\n",
    "   WHERE transaction_date >= NOW() - INTERVAL '1 HOUR'\n",
    "   GROUP BY customer_id\n",
    "   HAVING num_transactions > 5;\n",
    "   ```  \n",
    "   *Flags customers with 5+ transactions in the last hour for potential fraud review.*  \n",
    "\n",
    "---\n",
    "\n",
    "### **8. How do you measure customer lifetime value (CLV) for a credit card portfolio?**  \n",
    "**Sample Answer:**  \n",
    "To calculate **Customer Lifetime Value (CLV)**:  \n",
    "\n",
    "1. **Average Monthly Spend:** Identify the average spend per customer.  \n",
    "2. **Average Retention Period:** Determine how long customers keep the card.  \n",
    "3. **Net Revenue Per Customer:** Calculate revenue from interest, fees, and transactions.  \n",
    "4. **Apply the CLV Formula:**  \n",
    "   \\[\n",
    "   CLV = (Average Monthly Revenue × 12 × Retention Years) - Acquisition Cost\n",
    "   \\]  \n",
    "Example:  \n",
    "- **Monthly Revenue per customer:** $50  \n",
    "- **Retention Period:** 5 years  \n",
    "- **Acquisition Cost:** $200  \n",
    "\\[\n",
    "CLV = (50 × 12 × 5) - 200 = $2,800\n",
    "\\]  \n",
    "This helps **prioritize high-value customer segments** for marketing efforts.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Business Strategy & Product Innovation**  \n",
    "\n",
    "### **9. What are some emerging trends in the credit card industry?**  \n",
    "**Sample Answer:**  \n",
    "- **Digital & Virtual Cards:** Mobile wallets like Apple Pay and Google Pay are growing.  \n",
    "- **Personalized Rewards:** AI-driven recommendations for maximizing card benefits.  \n",
    "- **Buy Now, Pay Later (BNPL):** Short-term installment plans for purchases.  \n",
    "- **Sustainability:** Eco-friendly credit cards that reward green spending.  \n",
    "- **AI-driven Fraud Prevention:** Advanced machine learning models for detecting fraud.  \n",
    "\n",
    "Example: A **cashback credit card linked to sustainable purchases** could attract environmentally conscious consumers.  \n",
    "\n",
    "---\n",
    "\n",
    "### **10. How would you evaluate a new credit card product launch?**  \n",
    "**Sample Answer:**  \n",
    "I would evaluate success using:  \n",
    "\n",
    "1. **Customer Adoption Rate:** Number of new accounts opened.  \n",
    "2. **Activation Rate:** Percentage of customers actively using the card.  \n",
    "3. **Spend & Transaction Volume:** Total purchases made using the card.  \n",
    "4. **Retention & Churn Rate:** Percentage of users keeping the card over time.  \n",
    "5. **Profitability Metrics:** Interest income, interchange fees, and rewards costs.  \n",
    "\n",
    "**Example:** If a new **travel credit card** has **low activation rates**, I would recommend **offering a higher sign-up bonus or reducing annual fees**.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1454cf64-50d6-45e7-bc05-b5063ee31ec2",
   "metadata": {},
   "source": [
    "## **Scenario-Based Questions**  \n",
    "\n",
    "### **1. Scenario: Declining Credit Card Usage**  \n",
    "**Question:** You notice that credit card spending among existing customers has declined by 10% over the past six months. How would you analyze this issue and propose solutions?  \n",
    "\n",
    "**Sample Answer:**  \n",
    "1. **Data Analysis:**  \n",
    "   - Analyze **transaction history** to identify which customer segments are spending less.  \n",
    "   - Check for **seasonal trends** or macroeconomic factors affecting spending.  \n",
    "   - Review **customer feedback** to find potential pain points (e.g., high fees, reduced rewards).  \n",
    "\n",
    "2. **Hypothesis Testing:**  \n",
    "   - Are customers shifting spending to **competitor cards** with better rewards?  \n",
    "   - Is the **economic downturn** reducing discretionary spending?  \n",
    "   - Are there **technical issues** (e.g., card declines, fraud alerts) discouraging usage?  \n",
    "\n",
    "3. **Solution Proposal:**  \n",
    "   - **Rewards Optimization:** Introduce bonus cashback or category-based promotions.  \n",
    "   - **Personalized Offers:** Target dormant users with special incentives.  \n",
    "   - **Marketing Campaigns:** Educate customers on maximizing card benefits.  \n",
    "   - **Customer Engagement:** Gather feedback via surveys and support channels.  \n",
    "\n",
    "*Example:* If analysis shows that young professionals are switching to fintech credit cards, we might **introduce a millennial-friendly cashback structure (e.g., more rewards for streaming services and online shopping).**  \n",
    "\n",
    "---\n",
    "\n",
    "### **2. Scenario: Increase in Credit Card Defaults**  \n",
    "**Question:** Your team has noticed a **15% increase in credit card default rates** over the past quarter. What steps would you take to investigate and mitigate the risk?  \n",
    "\n",
    "**Sample Answer:**  \n",
    "1. **Root Cause Analysis:**  \n",
    "   - Segment customers based on **credit score, income level, and spending habits** to identify high-risk groups.  \n",
    "   - Analyze if the increase is concentrated in a specific **industry** (e.g., job losses in tech or retail sectors).  \n",
    "   - Check for **changes in lending policies** that may have led to riskier approvals.  \n",
    "\n",
    "2. **Mitigation Strategies:**  \n",
    "   - **Preemptive Risk Management:** Adjust credit limits for high-risk customers.  \n",
    "   - **Enhanced Collections Strategy:** Offer flexible repayment plans before accounts go delinquent.  \n",
    "   - **Tighter Underwriting:** Modify approval criteria based on new risk insights.  \n",
    "   - **Early Warning System:** Implement predictive analytics to flag at-risk accounts before default.  \n",
    "\n",
    "*Example:* If data shows that **defaults are rising among gig economy workers**, we might introduce a **\"payment holiday\" feature**, allowing them to skip payments during low-income months.  \n",
    "\n",
    "---\n",
    "\n",
    "### **3. Scenario: New Credit Card Product Evaluation**  \n",
    "**Question:** Your company is launching a **new travel rewards credit card**. How would you measure its success in the first year?  \n",
    "\n",
    "**Sample Answer:**  \n",
    "1. **Key Performance Indicators (KPIs):**  \n",
    "   - **Customer Acquisition:** Number of new accounts opened.  \n",
    "   - **Activation Rate:** Percentage of customers making at least one transaction in the first 60 days.  \n",
    "   - **Transaction Volume:** Total spend per customer, especially on travel-related purchases.  \n",
    "   - **Retention Rate:** Percentage of customers who renew after the first year.  \n",
    "   - **Interchange Fee Revenue:** Income from card transactions at merchants.  \n",
    "\n",
    "2. **Analysis Approach:**  \n",
    "   - Compare performance **against projected targets** and competitor benchmarks.  \n",
    "   - Segment users based on **spending patterns (frequent travelers vs. casual users).**  \n",
    "   - Monitor **customer feedback** to identify areas for product enhancement.  \n",
    "\n",
    "3. **Action Plan:**  \n",
    "   - If **activation rates are low**, launch a targeted **bonus miles** campaign.  \n",
    "   - If **transaction volume is low**, increase **reward multipliers for key spending categories (e.g., hotels, airlines).**  \n",
    "   - If **customer churn is high**, improve retention efforts with **fee waivers or anniversary rewards.**  \n",
    "\n",
    "*Example:* If analysis shows that **most cardholders use the card only for flights but not daily purchases**, we might introduce **higher cashback on dining and local transportation.**  \n",
    "\n",
    "---\n",
    "\n",
    "## **Case Study Questions**  \n",
    "\n",
    "### **4. Case Study: Optimizing a Credit Card Rewards Program**  \n",
    "**Question:** Your company’s credit card rewards program is underperforming, with **low customer engagement**. How would you revamp the program?  \n",
    "\n",
    "**Sample Answer:**  \n",
    "1. **Diagnose the Problem:**  \n",
    "   - Analyze **reward redemption rates**—are customers finding value in the rewards?  \n",
    "   - Compare with **competitor programs**—are they offering better incentives?  \n",
    "   - Survey customers to understand **frustrations (e.g., hard-to-redeem points, lack of relevant rewards).**  \n",
    "\n",
    "2. **Redesign the Rewards Structure:**  \n",
    "   - Introduce **dynamic rewards** that adjust based on spending categories.  \n",
    "   - Offer **personalized bonuses** based on customer preferences.  \n",
    "   - Reduce **redemption barriers** (e.g., lower minimum point requirements).  \n",
    "\n",
    "3. **Measure Success:**  \n",
    "   - Track changes in **card usage frequency and total spending volume.**  \n",
    "   - Monitor **customer satisfaction scores and retention rates.**  \n",
    "   - Compare against a **control group** to isolate the impact of the changes.  \n",
    "\n",
    "*Example:* If **younger customers prefer cashback over airline miles**, we might shift to a **hybrid model** where they can choose between **cashback, travel points, or merchant discounts.**  \n",
    "\n",
    "---\n",
    "\n",
    "### **5. Case Study: Fraud Detection & Prevention Strategy**  \n",
    "**Question:** Your company has detected an increase in **credit card fraud cases**. How would you tackle this issue?  \n",
    "\n",
    "**Sample Answer:**  \n",
    "1. **Identify Fraud Patterns:**  \n",
    "   - Use **SQL and analytics tools** to detect unusual transaction patterns.  \n",
    "   - Implement **machine learning models** to classify fraudulent vs. legitimate transactions.  \n",
    "   - Monitor common fraud types (e.g., **card-not-present fraud, account takeovers**).  \n",
    "\n",
    "2. **Enhance Security Measures:**  \n",
    "   - Strengthen **multi-factor authentication (MFA)** for online transactions.  \n",
    "   - Implement **AI-driven fraud alerts** with real-time customer notifications.  \n",
    "   - Introduce **spending limits on high-risk transactions** (e.g., international purchases).  \n",
    "\n",
    "3. **Evaluate Impact & Adjust Strategy:**  \n",
    "   - Track the **false positive rate** to ensure real customers aren’t being blocked unfairly.  \n",
    "   - Analyze **customer complaints** related to fraud prevention efforts.  \n",
    "   - Work with **law enforcement and cybersecurity teams** to prevent large-scale fraud.  \n",
    "\n",
    "*Example:* If **card-not-present fraud (e.g., online shopping scams) is increasing**, we might **partner with e-commerce platforms to introduce biometric authentication.**  \n",
    "\n",
    "---\n",
    "\n",
    "### **6. Case Study: Credit Card Pricing Strategy**  \n",
    "**Question:** Your company wants to **increase credit card fee revenue** without losing customers. What approach would you take?  \n",
    "\n",
    "**Sample Answer:**  \n",
    "1. **Analyze Current Pricing Structure:**  \n",
    "   - Compare **annual fees, late fees, and interest rates** with competitors.  \n",
    "   - Identify which fee types have **high customer sensitivity** (e.g., late payment fees).  \n",
    "   - Segment customers to understand **who is most affected by fee changes.**  \n",
    "\n",
    "2. **Adjust Fee Structure Strategically:**  \n",
    "   - Offer **tiered pricing** (e.g., basic, premium, and elite card options).  \n",
    "   - Introduce **waivers for high-value customers** to increase retention.  \n",
    "   - Increase fees **only on low-impact areas** (e.g., foreign transaction fees for domestic users).  \n",
    "\n",
    "3. **Measure & Optimize:**  \n",
    "   - Monitor **customer attrition rates** post-change.  \n",
    "   - Track **profitability improvements** across customer segments.  \n",
    "   - Use **customer feedback** to refine the pricing model further.  \n",
    "\n",
    "*Example:* If we **increase the annual fee from $99 to $129**, we might **add new premium benefits (e.g., free airport lounge access) to justify the price hike.**  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac57193d-4aba-455e-b64d-5ea05c3845ed",
   "metadata": {},
   "source": [
    "## **SQL-Based Scenarios**  \n",
    "\n",
    "### **1. Scenario: Identifying High-Spending Customers**  \n",
    "**Question:** Write an SQL query to find the **top 10 customers** who spent the most in the last 3 months.  \n",
    "\n",
    "**Sample SQL Query:**  \n",
    "```sql\n",
    "SELECT customer_id, SUM(transaction_amount) AS total_spent\n",
    "FROM transactions\n",
    "WHERE transaction_date >= CURRENT_DATE - INTERVAL '3 months'\n",
    "GROUP BY customer_id\n",
    "ORDER BY total_spent DESC\n",
    "LIMIT 10;\n",
    "```\n",
    "**Explanation:**  \n",
    "- Filters transactions from the **last 3 months**.  \n",
    "- Groups by `customer_id` to calculate **total spend per customer**.  \n",
    "- Orders in **descending order** to get top spenders.  \n",
    "\n",
    "---\n",
    "\n",
    "### **2. Scenario: Detecting Potential Fraud**  \n",
    "**Question:** Write an SQL query to find customers who made more than **5 transactions within 1 hour**.  \n",
    "\n",
    "**Sample SQL Query:**  \n",
    "```sql\n",
    "SELECT customer_id, COUNT(*) AS transaction_count\n",
    "FROM transactions\n",
    "WHERE transaction_time >= NOW() - INTERVAL '1 HOUR'\n",
    "GROUP BY customer_id\n",
    "HAVING COUNT(*) > 5;\n",
    "```\n",
    "**Explanation:**  \n",
    "- Filters transactions made in the **last hour**.  \n",
    "- Groups by `customer_id` to count their transactions.  \n",
    "- Filters customers who made **more than 5** transactions.  \n",
    "\n",
    "---\n",
    "\n",
    "### **3. Scenario: Analyzing Late Payments**  \n",
    "**Question:** Write an SQL query to find customers who have **missed at least 2 payments in the last 6 months**.  \n",
    "\n",
    "**Sample SQL Query:**  \n",
    "```sql\n",
    "SELECT customer_id, COUNT(*) AS missed_payments\n",
    "FROM payments\n",
    "WHERE status = 'missed'\n",
    "AND payment_date >= CURRENT_DATE - INTERVAL '6 months'\n",
    "GROUP BY customer_id\n",
    "HAVING COUNT(*) >= 2;\n",
    "```\n",
    "**Explanation:**  \n",
    "- Filters payments with `status = 'missed'`.  \n",
    "- Checks within the **last 6 months**.  \n",
    "- Groups by `customer_id` and filters those with **2+ missed payments**.  \n",
    "\n",
    "---\n",
    "\n",
    "### **4. Scenario: Finding Customers with High Credit Utilization**  \n",
    "**Question:** Identify customers whose **credit utilization** is above **80%** of their limit.  \n",
    "\n",
    "**Sample SQL Query:**  \n",
    "```sql\n",
    "SELECT c.customer_id, c.credit_limit, SUM(t.transaction_amount) AS total_spent,\n",
    "       (SUM(t.transaction_amount) / c.credit_limit) * 100 AS utilization_rate\n",
    "FROM customers c\n",
    "JOIN transactions t ON c.customer_id = t.customer_id\n",
    "WHERE transaction_date >= CURRENT_DATE - INTERVAL '1 month'\n",
    "GROUP BY c.customer_id, c.credit_limit\n",
    "HAVING (SUM(t.transaction_amount) / c.credit_limit) > 0.8;\n",
    "```\n",
    "**Explanation:**  \n",
    "- Joins **customers** with their **transactions**.  \n",
    "- Calculates **utilization rate** (`total_spent / credit_limit * 100`).  \n",
    "- Filters customers **exceeding 80% utilization**.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Python-Based Scenarios**  \n",
    "\n",
    "### **5. Scenario: Detecting Anomalous Spending Behavior**  \n",
    "**Question:** Write a Python script to flag transactions that are **3 times higher than a customer’s average transaction amount**.  \n",
    "\n",
    "**Sample Python Code:**  \n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample transaction data\n",
    "data = {\n",
    "    'customer_id': [101, 101, 102, 102, 103, 103, 103],\n",
    "    'transaction_id': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'amount': [50, 60, 100, 500, 30, 120, 700]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the average transaction per customer\n",
    "avg_spend = df.groupby('customer_id')['amount'].mean()\n",
    "\n",
    "# Flag transactions that are 3x higher than the average\n",
    "df['flagged'] = df.apply(lambda x: x['amount'] > 3 * avg_spend[x['customer_id']], axis=1)\n",
    "\n",
    "# Display flagged transactions\n",
    "print(df[df['flagged']])\n",
    "```\n",
    "**Explanation:**  \n",
    "- **Groups transactions** by customer ID to calculate their **average spend**.  \n",
    "- Flags any transaction that is **3x the average spend** for that customer.  \n",
    "- This helps detect **unusual spikes** that could indicate fraud.  \n",
    "\n",
    "---\n",
    "\n",
    "### **6. Scenario: Predicting Credit Card Churn Using Logistic Regression**  \n",
    "**Question:** Write a Python script using `sklearn` to build a **credit card churn prediction model**.  \n",
    "\n",
    "**Sample Python Code:**  \n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'credit_score': [750, 620, 680, 700, 590, 780, 810],\n",
    "    'total_spent': [5000, 2000, 3000, 4000, 1500, 6000, 7000],\n",
    "    'late_payments': [0, 3, 1, 0, 4, 0, 0],\n",
    "    'churn': [0, 1, 0, 0, 1, 0, 0]  # 1 = churned, 0 = active\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Features and target variable\n",
    "X = df[['credit_score', 'total_spent', 'late_payments']]\n",
    "y = df['churn']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "```\n",
    "**Explanation:**  \n",
    "- Uses **credit score, spending, and late payments** to predict churn.  \n",
    "- Splits data into **train and test sets**.  \n",
    "- Uses **RandomForestClassifier** for training.  \n",
    "- Evaluates performance using **accuracy score**.  \n",
    "\n",
    "---\n",
    "\n",
    "### **7. Scenario: SQL Query Execution in Python**  \n",
    "**Question:** How would you fetch customer transaction data from a SQL database using Python?  \n",
    "\n",
    "**Sample Python Code:**  \n",
    "```python\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('credit_card.db')\n",
    "\n",
    "# Query to fetch transactions\n",
    "query = \"\"\"\n",
    "SELECT customer_id, transaction_date, transaction_amount\n",
    "FROM transactions\n",
    "WHERE transaction_date >= DATE('now', '-6 months');\n",
    "\"\"\"\n",
    "\n",
    "# Execute query and load into a DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n",
    "\n",
    "# Display results\n",
    "print(df.head())\n",
    "```\n",
    "**Explanation:**  \n",
    "- **Connects** to an SQL database.  \n",
    "- Runs a query to fetch transactions **from the last 6 months**.  \n",
    "- Stores the results in a **Pandas DataFrame** for further analysis.  \n",
    "\n",
    "---\n",
    "\n",
    "### **8. Scenario: Creating a Monthly Spending Summary Report**  \n",
    "**Question:** Write a Python script to **group credit card transactions by month** and calculate total spending per customer.  \n",
    "\n",
    "**Sample Python Code:**  \n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'customer_id': [101, 101, 102, 102, 103, 103, 103],\n",
    "    'transaction_date': pd.to_datetime(['2024-01-15', '2024-02-10', '2024-01-20', \n",
    "                                         '2024-03-05', '2024-02-25', '2024-03-15', '2024-03-25']),\n",
    "    'transaction_amount': [150, 200, 300, 500, 100, 400, 600]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extract month from date\n",
    "df['month'] = df['transaction_date'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Group by customer and month\n",
    "monthly_spending = df.groupby(['customer_id', 'month'])['transaction_amount'].sum().reset_index()\n",
    "\n",
    "print(monthly_spending)\n",
    "```\n",
    "**Explanation:**  \n",
    "- **Extracts month** from transaction dates.  \n",
    "- Groups transactions by **customer ID and month**.  \n",
    "- Calculates **total spending per month** for each customer.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f80e6f7-ab39-4294-998b-c21b7a506155",
   "metadata": {},
   "source": [
    "## **Advanced SQL Scenarios**  \n",
    "\n",
    "### **1. Scenario: Identifying Customers with Unusual Spending Patterns**  \n",
    "**Question:** Find customers whose **monthly spending increased by more than 50% compared to the previous month**.  \n",
    "\n",
    "**Sample SQL Query:**  \n",
    "```sql\n",
    "WITH MonthlySpending AS (\n",
    "    SELECT customer_id, \n",
    "           DATE_TRUNC('month', transaction_date) AS txn_month,\n",
    "           SUM(transaction_amount) AS total_spent\n",
    "    FROM transactions\n",
    "    WHERE transaction_date >= CURRENT_DATE - INTERVAL '6 months'\n",
    "    GROUP BY customer_id, txn_month\n",
    "),\n",
    "MonthlyChange AS (\n",
    "    SELECT m1.customer_id, \n",
    "           m1.txn_month, \n",
    "           m1.total_spent AS current_month_spend, \n",
    "           m2.total_spent AS prev_month_spend,\n",
    "           ((m1.total_spent - m2.total_spent) / NULLIF(m2.total_spent, 0)) * 100 AS spend_increase_pct\n",
    "    FROM MonthlySpending m1\n",
    "    LEFT JOIN MonthlySpending m2 \n",
    "    ON m1.customer_id = m2.customer_id \n",
    "    AND m1.txn_month = m2.txn_month + INTERVAL '1 month'\n",
    ")\n",
    "SELECT customer_id, txn_month, current_month_spend, prev_month_spend, spend_increase_pct\n",
    "FROM MonthlyChange\n",
    "WHERE spend_increase_pct > 50;\n",
    "```\n",
    "**Explanation:**  \n",
    "1. Aggregates **monthly spending** for each customer.  \n",
    "2. Joins the data to calculate **month-over-month changes**.  \n",
    "3. Filters customers with **spending increase > 50%**.  \n",
    "\n",
    "---\n",
    "\n",
    "### **2. Scenario: Finding Customers with High Cash Advance Usage**  \n",
    "**Question:** Identify customers who have taken **cash advances more than 3 times in the past month** and spent over **$5,000 on cash advances**.  \n",
    "\n",
    "**Sample SQL Query:**  \n",
    "```sql\n",
    "SELECT customer_id, COUNT(*) AS cash_advance_count, SUM(transaction_amount) AS total_cash_advance\n",
    "FROM transactions\n",
    "WHERE transaction_type = 'cash_advance'\n",
    "AND transaction_date >= CURRENT_DATE - INTERVAL '1 month'\n",
    "GROUP BY customer_id\n",
    "HAVING COUNT(*) > 3 AND SUM(transaction_amount) > 5000;\n",
    "```\n",
    "**Explanation:**  \n",
    "- Filters **cash advance transactions**.  \n",
    "- Aggregates data to find **frequent and high-value users**.  \n",
    "\n",
    "---\n",
    "\n",
    "### **3. Scenario: Optimizing SQL Query Performance for Large Datasets**  \n",
    "**Question:** Your transaction table has **millions of records**. How would you improve the performance of this query?  \n",
    "\n",
    "```sql\n",
    "SELECT customer_id, COUNT(*) AS num_transactions\n",
    "FROM transactions\n",
    "WHERE transaction_date >= CURRENT_DATE - INTERVAL '1 year'\n",
    "GROUP BY customer_id;\n",
    "```\n",
    "**Optimized Approach:**  \n",
    "1. **Use Indexing:**  \n",
    "   ```sql\n",
    "   CREATE INDEX idx_transaction_date ON transactions(transaction_date);\n",
    "   ```  \n",
    "   - This speeds up filtering by `transaction_date`.  \n",
    "\n",
    "2. **Use Partitioning:**  \n",
    "   ```sql\n",
    "   CREATE TABLE transactions_partitioned \n",
    "   PARTITION BY RANGE (transaction_date) (\n",
    "       PARTITION p1 VALUES LESS THAN ('2024-01-01'),\n",
    "       PARTITION p2 VALUES LESS THAN ('2025-01-01')\n",
    "   );\n",
    "   ```  \n",
    "   - Partitions data by year for **faster query execution**.  \n",
    "\n",
    "3. **Use Approximate Aggregations for Large Data:**  \n",
    "   ```sql\n",
    "   SELECT customer_id, APPROX_COUNT_DISTINCT(transaction_id) AS num_transactions\n",
    "   FROM transactions\n",
    "   WHERE transaction_date >= CURRENT_DATE - INTERVAL '1 year'\n",
    "   GROUP BY customer_id;\n",
    "   ```  \n",
    "   - `APPROX_COUNT_DISTINCT` improves performance when **exact count is not needed**.  \n",
    "\n",
    "---\n",
    "\n",
    "### **4. Scenario: Credit Utilization Risk Analysis**  \n",
    "**Question:** Identify customers whose **credit utilization increased by more than 30% compared to the previous month**.  \n",
    "\n",
    "**Sample SQL Query:**  \n",
    "```sql\n",
    "WITH CreditUtilization AS (\n",
    "    SELECT c.customer_id, \n",
    "           DATE_TRUNC('month', t.transaction_date) AS txn_month,\n",
    "           SUM(t.transaction_amount) / c.credit_limit AS utilization_rate\n",
    "    FROM customers c\n",
    "    JOIN transactions t ON c.customer_id = t.customer_id\n",
    "    WHERE transaction_date >= CURRENT_DATE - INTERVAL '6 months'\n",
    "    GROUP BY c.customer_id, txn_month, c.credit_limit\n",
    "),\n",
    "UtilizationChange AS (\n",
    "    SELECT u1.customer_id, u1.txn_month, \n",
    "           u1.utilization_rate AS current_utilization, \n",
    "           u2.utilization_rate AS prev_utilization,\n",
    "           ((u1.utilization_rate - u2.utilization_rate) / NULLIF(u2.utilization_rate, 0)) * 100 AS utilization_change\n",
    "    FROM CreditUtilization u1\n",
    "    LEFT JOIN CreditUtilization u2 \n",
    "    ON u1.customer_id = u2.customer_id \n",
    "    AND u1.txn_month = u2.txn_month + INTERVAL '1 month'\n",
    ")\n",
    "SELECT customer_id, txn_month, current_utilization, prev_utilization, utilization_change\n",
    "FROM UtilizationChange\n",
    "WHERE utilization_change > 30;\n",
    "```\n",
    "**Explanation:**  \n",
    "- **Calculates credit utilization** for each customer.  \n",
    "- **Finds monthly changes** and filters users exceeding a **30% increase**.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Advanced Python Scenarios**  \n",
    "\n",
    "### **5. Scenario: Predicting Customer Default Risk**  \n",
    "**Question:** Build a **credit card default prediction model** using Python.  \n",
    "\n",
    "**Sample Python Code:**  \n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'credit_score': [750, 620, 680, 700, 590, 780, 810, 550, 520, 640],\n",
    "    'total_spent': [5000, 2000, 3000, 4000, 1500, 6000, 7000, 1000, 800, 2500],\n",
    "    'late_payments': [0, 3, 1, 0, 4, 0, 0, 5, 6, 2],\n",
    "    'default': [0, 1, 0, 0, 1, 0, 0, 1, 1, 1]  # 1 = defaulted, 0 = paid on time\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Features and target variable\n",
    "X = df[['credit_score', 'total_spent', 'late_payments']]\n",
    "y = df['default']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "```\n",
    "**Explanation:**  \n",
    "- Uses **credit score, spending, and late payments** to predict **default risk**.  \n",
    "- Trains a **RandomForestClassifier** and evaluates **accuracy**.  \n",
    "\n",
    "---\n",
    "\n",
    "### **6. Scenario: Anomaly Detection in Credit Card Transactions**  \n",
    "**Question:** Implement **anomaly detection** using Isolation Forest.  \n",
    "\n",
    "**Sample Python Code:**  \n",
    "```python\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "# Sample transaction amounts\n",
    "transactions = np.array([[50], [60], [100], [500], [30], [120], [7000]])  \n",
    "\n",
    "# Train Isolation Forest model\n",
    "model = IsolationForest(contamination=0.1, random_state=42)\n",
    "model.fit(transactions)\n",
    "\n",
    "# Predict anomalies (-1 = anomaly, 1 = normal)\n",
    "predictions = model.predict(transactions)\n",
    "print(predictions)\n",
    "```\n",
    "**Explanation:**  \n",
    "- Uses **Isolation Forest** to detect **fraudulent transactions**.  \n",
    "- Flags transactions significantly higher than **usual spending**.  \n",
    "\n",
    "---\n",
    "\n",
    "### **7. Scenario: Customer Segmentation Using K-Means Clustering**  \n",
    "**Question:** Cluster customers based on **spending behavior**.  \n",
    "\n",
    "**Sample Python Code:**  \n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Sample spending data\n",
    "data = [[5000], [2000], [3000], [4000], [1500], [6000], [7000]]\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(data)\n",
    "\n",
    "print(clusters)\n",
    "```\n",
    "**Explanation:**  \n",
    "- Uses **K-Means clustering** to segment customers based on **spending**.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1713c7-02ea-4c0b-a95f-024e75226535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
